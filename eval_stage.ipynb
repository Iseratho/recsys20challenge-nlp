{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.memory.offHeap.enabled" : "true",
        "spark.driver.memory" : "10g",
        "spark.memory.offHeap.size" : "16g",
        "spark.master" : "local[*]",
        "spark.executor.memory" : "10g"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# NLP RECSYS Eval Stage\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592170016855,
          "endTs" : 1592170018166
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import com.johnsnowlabs.nlp.SparkNLP\n",
        "import com.johnsnowlabs.nlp.annotator._\n",
        "import com.johnsnowlabs.nlp.base._\n",
        "import org.apache.spark.ml.{Pipeline, PipelineModel, Transformer}\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "import org.apache.spark.sql.functions.{udf,to_timestamp}\n",
        "import org.apache.spark.storage._\n",
        "import org.apache.spark.ml.feature._\n",
        "import org.apache.spark.ml.classification._\n",
        "import org.apache.spark.ml.linalg.DenseVector\n",
        "import org.apache.spark.ml.param.{Param, ParamMap}\n",
        "import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions.{col, explode, udf}\n",
        "import org.apache.spark.sql.types.{DataTypes, StructType}\n",
        "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "val dataDir = sys.env(\"HOME\") + \"/recsys2020\"\n",
        "val dsName = \"training1m\"\n",
        "val predName = \"retweet.csv\""
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592170018226,
          "endTs" : 1592170045944
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val df = spark.read.parquet(dataDir + s\"/${dsName}.parquet\")\n",
        "\n",
        "val schema = new StructType()\n",
        "    .add(\"tweet_id\", StringType, true)\n",
        "    .add(\"user_id\", StringType, true)\n",
        "    .add(\"out_pred\", DoubleType, true)\n",
        "\n",
        "val pred = spark.read.format(\"csv\")\n",
        "        .option(\"delimiter\", \",\")\n",
        "        .schema(schema)\n",
        "        .load(dataDir + s\"/${dsName}.tsv\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592170045965,
          "endTs" : 1592170046314
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "pred"
      ],
      "outputs" : [
        {
          "execution_count" : 3,
          "data" : {
            "text/plain" : [
              "[tweet_id: string, user_id: string ... 1 more field]"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "DataFrame"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592170046322,
          "endTs" : 1592170046611
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "df"
      ],
      "outputs" : [
        {
          "execution_count" : 4,
          "data" : {
            "text/plain" : [
              "[user_id: string, tweet_id: string ... 17 more fields]"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "DataFrame"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592170046617,
          "endTs" : 1592170047155
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val joined = pred.join(df, Seq(\"user_id\", \"tweet_id\"), \"outer\")\n",
        "joined"
      ],
      "outputs" : [
        {
          "execution_count" : 5,
          "data" : {
            "text/plain" : [
              "[user_id: string, tweet_id: string ... 18 more fields]"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "DataFrame"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592170047166,
          "endTs" : 1592170060535
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Select (prediction, true label) and compute test error.\n",
        "val evaluator = new MulticlassClassificationEvaluator()\n",
        "  .setLabelCol(\"has_retweet\")\n",
        "  .setPredictionCol(\"out_pred\")\n",
        "  .setMetricName(\"f1\")\n",
        "val f1 = evaluator.evaluate(joined)\n",
        "println(s\"F1 = ${f1}\")"
      ],
      "outputs" : [
        {
          "ename" : "org.apache.spark.SparkException",
          "evalue" : "Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 17, localhost, executor driver): scala.MatchError: [null,null] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator$$anonfun$1.apply(MulticlassClassificationEvaluator.scala:79)\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator$$anonfun$1.apply(MulticlassClassificationEvaluator.scala:79)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:193)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:",
          "traceback" : [
          ],
          "output_type" : "error"
        }
      ]
    }
  ]
}