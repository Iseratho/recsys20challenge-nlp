{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.memory.offHeap.enabled" : "true",
        "spark.driver.memory" : "20g",
        "spark.memory.offHeap.size" : "32g",
        "spark.master" : "local[*]",
        "spark.executor.memory" : "20g",
        "spark.local.dir" : "/home/sko/.cache/spark"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# NLP RECSYS Run Pipeline Stage1\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592077863524,
          "endTs" : 1592077864378
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import com.johnsnowlabs.nlp.SparkNLP\n",
        "import com.johnsnowlabs.nlp.annotator._\n",
        "import com.johnsnowlabs.nlp.base._\n",
        "import org.apache.spark.ml.{Pipeline, PipelineModel, Transformer}\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "import org.apache.spark.sql.functions.{udf,to_timestamp}\n",
        "import org.apache.spark.storage._\n",
        "import org.apache.spark.ml.feature._\n",
        "import org.apache.spark.ml.classification._\n",
        "import org.apache.spark.ml.linalg.DenseVector\n",
        "import org.apache.spark.ml.param.{Param, ParamMap}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions.{col, explode, udf}\n",
        "import org.apache.spark.sql.types.{DataTypes, StructType}\n",
        "\n",
        "val dataDir = sys.env(\"HOME\") + \"/recsys2020\""
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592077864397,
          "endTs" : 1592077865624
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "package nlprecsys\n",
        "import com.johnsnowlabs.nlp.SparkNLP\n",
        "import com.johnsnowlabs.nlp.annotator._\n",
        "import com.johnsnowlabs.nlp.base._\n",
        "import org.apache.spark.ml.{Pipeline, PipelineModel, Transformer}\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "import org.apache.spark.sql.functions.{udf,to_timestamp}\n",
        "import org.apache.spark.storage._\n",
        "import org.apache.spark.ml.feature._\n",
        "import org.apache.spark.ml.classification._\n",
        "import org.apache.spark.ml.linalg.DenseVector\n",
        "import org.apache.spark.ml.param.{Param, ParamMap}\n",
        "import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions.{col, explode, udf}\n",
        "import org.apache.spark.sql.types.{DataTypes, StructType}\n",
        "\n",
        "class Exploder(override val uid: String) extends Transformer with DefaultParamsWritable {\n",
        "  def this() = this(Identifiable.randomUID(\"Exploder\"))\n",
        "  def setInputCol(value: String): this.type = set(inputCol, value)\n",
        "  def setOutputCol(value: String): this.type = set(outputCol, value)\n",
        "  def getOutputCol: String = getOrDefault(outputCol)\n",
        "  val inputCol = new Param[String](this, \"inputCol\", \"input column\")\n",
        "  val outputCol = new Param[String](this, \"outputCol\", \"output column\")\n",
        "\n",
        "  override def transform(dataset: Dataset[_]): DataFrame = {\n",
        "    val outCol = extractParamMap.getOrElse(outputCol, \"output\")\n",
        "    val inCol = extractParamMap.getOrElse(inputCol, \"input\")\n",
        "    dataset.withColumn(outCol, explode(col(inCol)))\n",
        "  }\n",
        "\n",
        "  override def transformSchema(schema: StructType): StructType = {\n",
        "      val outCol = extractParamMap.getOrElse(outputCol, \"output\")\n",
        "      val inCol = extractParamMap.getOrElse(inputCol, \"input\")\n",
        "      val inputColType = schema.fields(schema.fieldIndex(inCol)).dataType.asInstanceOf[ArrayType];\n",
        "      schema.add(outCol, inputColType.elementType)\n",
        "  }\n",
        "  override def copy(extra: ParamMap): Transformer = defaultCopy(extra)\n",
        "}\n",
        "object Exploder extends DefaultParamsReadable[Exploder] {\n",
        "  override def load(path: String): Exploder = super.load(path)\n",
        "}\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592077865630,
          "endTs" : 1592078465474
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val pipeline = PipelineModel.load(dataDir + \"/pipeline_stage1_v1\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592079850564
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val dsName = \"training\"\n",
        "\n",
        "val classNames = Array(\n",
        "  \"retweet\",\n",
        "  \"retweet_with_comment\",\n",
        "  \"like\",\n",
        "  \"reply\")\n",
        "val labelColumns = for (className <- classNames) yield \"has_\" + className;\n",
        "val df = spark.read.parquet(dataDir + s\"/${dsName}.parquet\")\n",
        "val trans_df = pipeline.transform(df).selectExpr((Array(\"tweet_id\", \"user_id\", \"features\") ++ labelColumns):_*)\n",
        "\n",
        "trans_df\n",
        "    .write\n",
        "    .mode(SaveMode.Overwrite)\n",
        "    .parquet(dataDir + s\"/${dsName}_stage1.parquet\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592078970448,
          "endTs" : 1592078971211
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "trans_df.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+--------------------+--------------------+--------------------+-----------+------------------------+--------+---------+\n",
            "|            tweet_id|             user_id|            features|has_retweet|has_retweet_with_comment|has_like|has_reply|\n",
            "+--------------------+--------------------+--------------------+-----------+------------------------+--------+---------+\n",
            "|FB6304C97F6CC05AF...|D0EA9DDFE93EDA782...|[0.06471998244524...|          0|                       0|       1|        0|\n",
            "|8A025814338D4CAB5...|5CD17BD84873464C2...|[0.01755615323781...|          0|                       0|       0|        0|\n",
            "|8E8EC11B9492B6C09...|6B8C5EFC300170EF8...|[0.02887635119259...|          0|                       0|       0|        0|\n",
            "|D59F5C535C7C892D7...|2F5D9BFEBEB24F290...|[0.05812061950564...|          0|                       0|       0|        0|\n",
            "|7D6700DA02116E216...|073770D7360B4F399...|[0.07400916516780...|          0|                       0|       1|        0|\n",
            "|E5A3EC400A664F07A...|131815196691D79E6...|[0.05579914152622...|          1|                       0|       1|        0|\n",
            "|CB64C7FCF54EFA087...|A428C660D9B2836A5...|[-0.0019894882570...|          0|                       0|       0|        0|\n",
            "|56F2DECBE23F80BC6...|09D5EE66D2D3DED2F...|[0.04972360655665...|          0|                       0|       0|        0|\n",
            "|D52193C9683532137...|72687F8AAA94CE60D...|[0.00112285930663...|          0|                       0|       0|        0|\n",
            "|C801AB5F48C7B7ADE...|7B7436B9BC41DB552...|[0.06297096610069...|          0|                       0|       0|        0|\n",
            "|1C7A70F249B9E6083...|DC208675234315A18...|[0.05471624061465...|          0|                       0|       0|        0|\n",
            "|3E3C4C133094A20A2...|231EF63050C2835BD...|[0.05166580155491...|          0|                       0|       1|        0|\n",
            "|36EA7F9D7052C540A...|5E9F1CA08E3405C89...|[0.03256233409047...|          0|                       0|       0|        0|\n",
            "|A8B22B7662AB9F86A...|D19877D507639A988...|[0.06377896666526...|          0|                       0|       1|        0|\n",
            "|478C06E2B0148F808...|87E555A6E65962920...|[0.00124520168174...|          1|                       0|       0|        0|\n",
            "|6D7A346F142C22FBA...|B159B899A0756E8A5...|[0.04949069395661...|          0|                       0|       1|        0|\n",
            "|FCEBA305125450DA3...|118959453B6025307...|[0.03157019242644...|          0|                       0|       0|        0|\n",
            "|0F513DC063E902BFC...|E2FF894A4228C37B7...|[0.02252185717225...|          0|                       0|       0|        0|\n",
            "|98C4564664C6BF882...|CD66CFE5540A02880...|[0.05670445784926...|          0|                       0|       0|        0|\n",
            "|09BD59FE47907DEC0...|86CBCDA0E3C9393C6...|[0.03702759742736...|          0|                       0|       1|        0|\n",
            "+--------------------+--------------------+--------------------+-----------+------------------------+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592078971216,
          "endTs" : 1592078971389
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    }
  ]
}