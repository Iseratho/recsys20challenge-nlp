{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0",
          "com.microsoft.ml.spark:mmlspark_2.11:0.18.1"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.memory.offHeap.enabled" : "true",
        "spark.driver.memory" : "4g",
        "spark.memory.offHeap.size" : "32g",
        "spark.master" : "local[*]",
        "spark.executor.memory" : "8g",
        "spark.local.dir" : "/var/cache/spark"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# NLP RECSYS Train Pipeline Stage2\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320651027,
          "endTs" : 1592320651812
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import com.johnsnowlabs.nlp.SparkNLP\n",
        "import com.johnsnowlabs.nlp.annotator._\n",
        "import com.johnsnowlabs.nlp.base._\n",
        "import com.johnsnowlabs.ml.tensorflow.TensorflowBert\n",
        "import org.apache.spark.ml.Pipeline\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "import org.apache.spark.sql.functions.{udf,to_timestamp}\n",
        "import org.apache.spark.storage._\n",
        "import org.apache.spark.ml.feature._\n",
        "import org.apache.spark.ml.classification._\n",
        "import org.apache.spark.ml.linalg.DenseVector\n",
        "\n",
        "import org.apache.spark.ml.Transformer\n",
        "import org.apache.spark.ml.param.{Param, ParamMap}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions.{col, explode, udf}\n",
        "import org.apache.spark.sql.types.{DataTypes, StructType}\n",
        "\n",
        "import org.apache.spark.ml.linalg.Vectors\n",
        "\n",
        "\n",
        "val dataDir = sys.env(\"HOME\") + \"/recsys2020\"\n",
        "val dsName = \"training1m\""
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320651841,
          "endTs" : 1592320681699
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val df = spark.read.parquet(dataDir + s\"/${dsName}_stage1.parquet\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320681710,
          "endTs" : 1592320684127
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val classNames = Array(\n",
        "  \"retweet\",\n",
        "  \"retweet_with_comment\",\n",
        "  \"like\",\n",
        "  \"reply\")\n",
        "\n",
        "val tweetTypeIndexer = new StringIndexerModel(Array(\"TopLevel\", \"Retweet\", \"Quote\", \"Reply\"))\n",
        "  .setInputCol(\"tweet_type\")\n",
        "  .setOutputCol(\"tweet_type_idx\");\n",
        "\n",
        "val tweetTypeEncoder = new OneHotEncoder()\n",
        "  .setInputCol(tweetTypeIndexer.getOutputCol)\n",
        "  .setOutputCol(\"tweet_type_onehot\")\n",
        "\n",
        "// val scaleAss = new VectorAssembler()\n",
        "//   .setInputCols(Array(\n",
        "\n",
        "//   ))\n",
        "//   .setOutputCol(\"count_features\")\n",
        "\n",
        "// val scaler = new StandardScaler()\n",
        "//   .setInputCol(scaleAss.getOutputCol)\n",
        "//   .setOutputCol(\"count_features_scaled\")\n",
        "//   .setWithStd(true)\n",
        "//   .setWithMean(false)\n",
        "\n",
        "val ass = new VectorAssembler()\n",
        "  .setInputCols(Array(\n",
        "         \"embeddings\",\n",
        "          tweetTypeEncoder.getOutputCol,\n",
        "          \"author_follower_count\", \n",
        "          \"author_following_count\", \n",
        "          \"user_follower_count\", \n",
        "          \"user_following_count\", \n",
        "          \"num_hashtags\",\n",
        "          \"num_media\",\n",
        "          \"num_links\",\n",
        "          \"num_domains\",\n",
        "          \"author_is_verified\",\n",
        "          \"user_is_verified\",\n",
        "          \"follows\"\n",
        "    ))\n",
        "  .setOutputCol(\"features\")\n",
        "\n",
        "val classifiers = for (className <- classNames) yield new GBTClassifier()\n",
        "                        .setLabelCol(\"has_\" + className)\n",
        "                        .setFeaturesCol(\"features\")\n",
        "                        .setProbabilityCol(\"prob_\" + className)\n",
        "                        .setPredictionCol(\"pred_\" + className)\n",
        "                        .setRawPredictionCol(\"predraw_\" + className)\n",
        "                        .setFeatureSubsetStrategy(\"auto\");\n",
        "\n",
        "val pred_pipeline = new Pipeline().setStages(Array(tweetTypeIndexer, tweetTypeEncoder, ass) ++ classifiers)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320684134
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val udf_bool_to_int = udf[Integer, Boolean](x => if (x) 1 else 0)\n",
        "\n",
        "val df_with_ints = df\n",
        "    .withColumn(\"has_retweet\", udf_bool_to_int(col(\"has_retweet\")))\n",
        "    .withColumn(\"has_retweet_with_comment\", udf_bool_to_int(col(\"has_retweet_with_comment\")))\n",
        "    .withColumn(\"has_like\", udf_bool_to_int(col(\"has_like\")))\n",
        "    .withColumn(\"has_reply\", udf_bool_to_int(col(\"has_reply\")))\n",
        "\n",
        "val convertUDF = udf((array : Seq[Float]) => {\n",
        "  Vectors.dense(array.toArray.map(_.toDouble))\n",
        "})\n",
        "\n",
        "val df_with_embeddings = df_with_ints\n",
        "        .withColumn(\"embeddings\", convertUDF('embeddings))\n",
        "\n",
        "val fitted_pipeline = pred_pipeline.fit(df_with_embeddings)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320447079,
          "endTs" : 1592320447294
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "fitted_pipeline.write.overwrite().save(dataDir + \"/pipeline_stage2_v2\")"
      ],
      "outputs" : [
        {
          "execution_count" : 5,
          "data" : {
            "application/json" : [
              {
                "pos" : {
                  "sourceId" : "Cell5",
                  "start" : 0,
                  "end" : 15,
                  "point" : 0
                },
                "msg" : "not found: value fitted_pipeline",
                "severity" : 2
              }
            ],
            "text/plain" : [
              "Error: not found: value fitted_pipeline (0)"
            ]
          },
          "metadata" : {
            "rel" : "compiler_errors"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320154513,
          "endTs" : 1592320154752
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "var res = fitted_pipeline.transform(df_with_embeddings)\n",
        "// only get relevant columns\n",
        "val toArr: Any => Double = _.asInstanceOf[DenseVector].toArray(1)\n",
        "val toArrUdf = udf(toArr)\n",
        "val labelColumns = for (className <- classNames) yield \"has_\" + className;\n",
        "\n",
        "\n",
        "val outputNames = for (className <- classNames) yield {\n",
        "    val inputName = \"prob_\" + className;\n",
        "    val outputName = \"out_\" + className;\n",
        "    res = res.withColumn(outputName, toArrUdf(col(inputName)));\n",
        "    outputName\n",
        "}\n",
        "\n",
        "res.selectExpr((Array(\"user_id\", \"tweet_id\") ++ labelColumns ++ outputNames):_*).show()"
      ],
      "outputs" : [
        {
          "execution_count" : 6,
          "data" : {
            "application/json" : [
              {
                "pos" : {
                  "sourceId" : "Cell6",
                  "start" : 10,
                  "end" : 25,
                  "point" : 10
                },
                "msg" : "not found: value fitted_pipeline",
                "severity" : 2
              },
              {
                "pos" : {
                  "sourceId" : "Cell6",
                  "start" : 36,
                  "end" : 54,
                  "point" : 36
                },
                "msg" : "not found: value df_with_embeddings",
                "severity" : 2
              }
            ],
            "text/plain" : [
              "Error: not found: value fitted_pipeline (10)",
              "Error: not found: value df_with_embeddings (36)"
            ]
          },
          "metadata" : {
            "rel" : "compiler_errors"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320154756,
          "endTs" : 1592320154814
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "res.show(false)"
      ],
      "outputs" : [
        {
          "execution_count" : 7,
          "data" : {
            "application/json" : [
              {
                "pos" : {
                  "sourceId" : "Cell7",
                  "start" : 0,
                  "end" : 3,
                  "point" : 0
                },
                "msg" : "not found: value res",
                "severity" : 2
              }
            ],
            "text/plain" : [
              "Error: not found: value res (0)"
            ]
          },
          "metadata" : {
            "rel" : "compiler_errors"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 8,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320154822,
          "endTs" : 1592320155839
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val val_df = spark.read.parquet(dataDir + s\"/val_stage1.parquet\")\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 9,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320155846,
          "endTs" : 1592320155891
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "var finalDf = fitted_pipeline.transform(val_df)\n",
        "finalDf.show()"
      ],
      "outputs" : [
        {
          "execution_count" : 9,
          "data" : {
            "application/json" : [
              {
                "pos" : {
                  "sourceId" : "Cell9",
                  "start" : 14,
                  "end" : 29,
                  "point" : 14
                },
                "msg" : "not found: value fitted_pipeline",
                "severity" : 2
              }
            ],
            "text/plain" : [
              "Error: not found: value fitted_pipeline (14)"
            ]
          },
          "metadata" : {
            "rel" : "compiler_errors"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 10,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320155896,
          "endTs" : 1592320156008
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// only get relevant columns\n",
        "val toArr: Any => Double = _.asInstanceOf[DenseVector].toArray(1)\n",
        "val toArrUdf = udf(toArr)\n",
        "\n",
        "var finalFinalDf = finalDf;\n",
        "val outputNames = for (className <- classNames) yield {\n",
        "    val inputName = \"prob_\" + className;\n",
        "    val outputName = \"out_\" + className;\n",
        "    finalFinalDf = finalFinalDf.withColumn(outputName, toArrUdf(col(inputName)));\n",
        "    outputName\n",
        "}\n",
        "\n",
        "finalFinalDf.selectExpr((Array(\"user_id\", \"tweet_id\") ++ outputNames):_*).show()"
      ],
      "outputs" : [
        {
          "execution_count" : 10,
          "data" : {
            "application/json" : [
              {
                "pos" : {
                  "sourceId" : "Cell10",
                  "start" : 141,
                  "end" : 148,
                  "point" : 141
                },
                "msg" : "not found: value finalDf",
                "severity" : 2
              }
            ],
            "text/plain" : [
              "Error: not found: value finalDf (141)"
            ]
          },
          "metadata" : {
            "rel" : "compiler_errors"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 11,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320156012,
          "endTs" : 1592320156131
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "for (className <- classNames) {\n",
        "    finalFinalDf.select($\"tweet_id\", $\"user_id\", col(\"out_\" + className)).write.format(\"csv\").option(\"header\", \"false\").save(dataDir + \"/\" + className + \".csv\")\n",
        "}"
      ],
      "outputs" : [
        {
          "execution_count" : 11,
          "data" : {
            "application/json" : [
              {
                "pos" : {
                  "sourceId" : "Cell11",
                  "start" : 36,
                  "end" : 48,
                  "point" : 36
                },
                "msg" : "not found: value finalFinalDf",
                "severity" : 2
              }
            ],
            "text/plain" : [
              "Error: not found: value finalFinalDf (36)"
            ]
          },
          "metadata" : {
            "rel" : "compiler_errors"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 12,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592320156134,
          "endTs" : 1592320156264
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    }
  ]
}