{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.memory.offHeap.enabled" : "true",
        "spark.driver.memory" : "12g",
        "spark.memory.offHeap.size" : "32g",
        "spark.master" : "local[*]",
        "spark.executor.memory" : "12g",
        "spark.local.dir" : "/var/cache/spark"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "code",
      "execution_count" : 0,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592345146012,
          "endTs" : 1592345146261
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 1,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# NLP RECSYS Run Pipeline Stage1\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592345146271,
          "endTs" : 1592345147115
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import com.johnsnowlabs.nlp.SparkNLP\n",
        "import com.johnsnowlabs.nlp.annotator._\n",
        "import com.johnsnowlabs.nlp.base._\n",
        "import org.apache.spark.ml.{Pipeline, PipelineModel, Transformer}\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "import org.apache.spark.sql.functions.{udf,to_timestamp}\n",
        "import org.apache.spark.storage._\n",
        "import org.apache.spark.ml.feature._\n",
        "import org.apache.spark.ml.classification._\n",
        "import org.apache.spark.ml.linalg.DenseVector\n",
        "import org.apache.spark.ml.param.{Param, ParamMap}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions.{col, explode, udf}\n",
        "import org.apache.spark.sql.types.{DataTypes, StructType}\n",
        "\n",
        "import org.apache.spark.ml.linalg.Vectors\n",
        "\n",
        "\n",
        "val dataDir = sys.env(\"HOME\") + \"/recsys2020\"\n",
        "val dsName = \"val10k\"\n",
        "\n",
        "val classNames = Array(\n",
        "  \"retweet\",\n",
        "  \"retweet_with_comment\",\n",
        "  \"like\",\n",
        "  \"reply\")\n",
        "val labelColumns = for (className <- classNames) yield \"has_\" + className;"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592345147128,
          "endTs" : 1592345182433
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val pipeline = PipelineModel.load(dataDir + \"/pipeline_stage2_v2\")\n",
        "val df = spark.read.parquet(dataDir + s\"/${dsName}_stage1.parquet\")\n",
        "val udf_bool_to_int = udf[Integer, Boolean](x => if (x) 1 else 0)\n",
        "\n",
        "val df_with_ints = df\n",
        "    .withColumn(\"has_retweet\", udf_bool_to_int(col(\"has_retweet\")))\n",
        "    .withColumn(\"has_retweet_with_comment\", udf_bool_to_int(col(\"has_retweet_with_comment\")))\n",
        "    .withColumn(\"has_like\", udf_bool_to_int(col(\"has_like\")))\n",
        "    .withColumn(\"has_reply\", udf_bool_to_int(col(\"has_reply\")))\n",
        "\n",
        "val convertUDF = udf((array : Seq[Float]) => {\n",
        "  Vectors.dense(array.toArray.map(_.toDouble))\n",
        "})\n",
        "\n",
        "val df_with_embeddings = df_with_ints\n",
        "        .withColumn(\"embeddings\", convertUDF('embeddings))\n",
        "\n",
        "val resDf = pipeline.transform(df_with_embeddings)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592345182440,
          "endTs" : 1592345182565
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "resDf.printSchema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "root\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- tweet_id: string (nullable = true)\n",
            " |-- tweet_type: string (nullable = true)\n",
            " |-- tokens: array (nullable = true)\n",
            " |    |-- element: integer (containsNull = true)\n",
            " |-- author_follower_count: integer (nullable = true)\n",
            " |-- author_following_count: integer (nullable = true)\n",
            " |-- author_is_verified: boolean (nullable = true)\n",
            " |-- user_follower_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_is_verified: boolean (nullable = true)\n",
            " |-- follows: boolean (nullable = true)\n",
            " |-- num_hashtags: integer (nullable = true)\n",
            " |-- num_media: integer (nullable = true)\n",
            " |-- num_links: integer (nullable = true)\n",
            " |-- num_domains: integer (nullable = true)\n",
            " |-- num_tokens: integer (nullable = true)\n",
            " |-- tweet_timestamp: integer (nullable = true)\n",
            " |-- hashtags: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- present_media: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- present_domains: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- has_retweet: integer (nullable = true)\n",
            " |-- has_retweet_with_comment: integer (nullable = true)\n",
            " |-- has_like: integer (nullable = true)\n",
            " |-- has_reply: integer (nullable = true)\n",
            " |-- embeddings: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- predraw_retweet: vector (nullable = true)\n",
            " |-- prob_retweet: vector (nullable = true)\n",
            " |-- pred_retweet: double (nullable = false)\n",
            " |-- predraw_retweet_with_comment: vector (nullable = true)\n",
            " |-- prob_retweet_with_comment: vector (nullable = true)\n",
            " |-- pred_retweet_with_comment: double (nullable = false)\n",
            " |-- predraw_like: vector (nullable = true)\n",
            " |-- prob_like: vector (nullable = true)\n",
            " |-- pred_like: double (nullable = false)\n",
            " |-- predraw_reply: vector (nullable = true)\n",
            " |-- prob_reply: vector (nullable = true)\n",
            " |-- pred_reply: double (nullable = false)\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592345182568,
          "endTs" : 1592345183477
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// only get relevant columns\n",
        "val toArr: Any => Double = _.asInstanceOf[DenseVector].toArray(1)\n",
        "val toArrUdf = udf(toArr)\n",
        "\n",
        "var tmpDf = resDf;\n",
        "val outputNames = for (className <- classNames) yield {\n",
        "    val inputName = \"prob_\" + className;\n",
        "    val outputName = \"out_\" + className;\n",
        "    tmpDf = tmpDf.withColumn(outputName, toArrUdf(col(inputName)));\n",
        "    outputName\n",
        "}\n",
        "val cleanDf = tmpDf.selectExpr((Array(\"user_id\", \"tweet_id\") ++ outputNames):_*)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592345183484,
          "endTs" : 1592345188268
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// write separate csv files for submission\n",
        "for (className <- classNames) {\n",
        "    cleanDf.select(col(\"tweet_id\"), \n",
        "                 col(\"user_id\"), \n",
        "                 col(\"out_\" + className))\n",
        "          .write.format(\"csv\")\n",
        "          .mode(SaveMode.Overwrite)\n",
        "          .option(\"header\", \"false\")\n",
        "          .save(dataDir + s\"/out/${dsName}/${className}.csv\")\n",
        "}"
      ],
      "outputs" : [
      ]
    }
  ]
}