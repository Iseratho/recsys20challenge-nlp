{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.memory.offHeap.enabled" : "true",
        "spark.driver.memory" : "12g",
        "spark.memory.offHeap.size" : "32g",
        "spark.master" : "local[*]",
        "spark.executor.memory" : "2g"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# pipeline test\n",
        "\n",
        "This is a text cell. Start editing!"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1591965700346,
          "endTs" : 1591965700657
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import com.johnsnowlabs.nlp.SparkNLP\n",
        "import com.johnsnowlabs.nlp.annotator._\n",
        "import com.johnsnowlabs.nlp.base._\n",
        "import com.johnsnowlabs.ml.tensorflow.TensorflowBert\n",
        "import org.apache.spark.ml.Pipeline\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "import org.apache.spark.sql.functions.{udf,to_timestamp}\n",
        "import org.apache.spark.ml.feature.QuantileDiscretizer\n",
        "import org.apache.spark.storage._\n",
        "\n",
        "val dataDir = \"../../data/recsys2020\""
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1591965700662,
          "endTs" : 1591965700841
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// val df = spark.read.parquet(dataDir + \"/training1m.parquet\").limit(1000).persist(StorageLevel.MEMORY_ONLY) // Remove limit after experiments\n",
        "// df"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1591965700848,
          "endTs" : 1591965701022
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Convert targets\n",
        "// val udf_has_engagement = udf[Int, IntegerType](x => if (x != null) 1 else 0)\n",
        "// var trans_df = df.withColumn(\"has_retweet\", udf_has_engagement('retweet_timestamp))\n",
        "// trans_df"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1591965701026,
          "endTs" : 1591965701669
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val trainDf = Seq(0 to 100:_*).toDF().withColumn(\"text\", lit(\"Hello World\"))\n",
        "    .withColumn(\"target1\", when(rand() > 0.3, 1).otherwise(0))\n",
        "    .withColumn(\"target2\", when(rand() > 0.6, 1).otherwise(0))\n",
        "trainDf.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+-----+-----------+-------+-------+\n",
            "|value|       text|target1|target2|\n",
            "+-----+-----------+-------+-------+\n",
            "|    0|Hello World|      0|      1|\n",
            "|    1|Hello World|      1|      0|\n",
            "|    2|Hello World|      1|      1|\n",
            "|    3|Hello World|      1|      0|\n",
            "|    4|Hello World|      1|      1|\n",
            "|    5|Hello World|      1|      0|\n",
            "|    6|Hello World|      1|      1|\n",
            "|    7|Hello World|      1|      1|\n",
            "|    8|Hello World|      1|      0|\n",
            "|    9|Hello World|      0|      0|\n",
            "|   10|Hello World|      1|      0|\n",
            "|   11|Hello World|      0|      0|\n",
            "|   12|Hello World|      0|      1|\n",
            "|   13|Hello World|      1|      1|\n",
            "|   14|Hello World|      1|      1|\n",
            "|   15|Hello World|      1|      0|\n",
            "|   16|Hello World|      1|      0|\n",
            "|   17|Hello World|      1|      1|\n",
            "|   18|Hello World|      0|      1|\n",
            "|   19|Hello World|      0|      0|\n",
            "+-----+-----------+-------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1591966202513
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val doc = new DocumentAssembler()\n",
        "    .setInputCol(\"text\")\n",
        "    .setOutputCol(\"document\")\n",
        "    .setCleanupMode(\"shrink\")\n",
        "// val tok = new Tokenizer()\n",
        "//     .setInputCols(\"document\")\n",
        "//     .setOutputCol(\"token\")\n",
        "//     .setContextChars(Array(\"(\", \")\", \"?\", \"!\"))\n",
        "//     .setSplitChars(Array(\"-\"))\n",
        "//     .addException(\"New York\")\n",
        "//     .addException(\"e-mail\")\n",
        "// val bert = BertEmbeddings.pretrained(name=\"bert_multi_cased\", lang=\"xx\")\n",
        "//       .setInputCols(\"document\", \"token\")\n",
        "//       .setOutputCol(\"embeddings\")\n",
        "//       .setPoolingLayer(0) // 0, -1, or -2\n",
        "val use = UniversalSentenceEncoder\n",
        "      .pretrained()\n",
        "      .setInputCols(Array(\"document\"))\n",
        "      .setOutputCol(\"tweet_embeddings\")\n",
        "// val emb = new SentenceEmbeddings()\n",
        "//       .setInputCols(Array(\"document\", \"embeddings\"))\n",
        "//       .setOutputCol(\"tweet_embeddings\")\n",
        "//       .setPoolingStrategy(\"AVERAGE\")\n",
        "val fin = new EmbeddingsFinisher()\n",
        "      .setInputCols(\"tweet_embeddings\")\n",
        "      .setOutputCols(\"finished_tweet_embeddings\")\n",
        "      .setOutputAsVector(true)\n",
        "      .setCleanAnnotations(false)\n",
        "\n",
        "// val use_clf_pipeline = new Pipeline().setStages(Array(doc, tok, bert, emb, fin))\n",
        "val use_clf_pipeline = new Pipeline().setStages(Array(doc, use, fin))"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "Download done! Loading the resource.\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "use_clf_pipeline.fit(testDf).transform(testDf)"
      ],
      "outputs" : [
      ]
    }
  ]
}