{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.memory.offHeap.enabled" : "true",
        "spark.driver.memory" : "10g",
        "spark.memory.offHeap.size" : "16g",
        "spark.master" : "local[*]",
        "spark.executor.memory" : "10g"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# NLP RECSYS Eval Stage\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592346941130,
          "endTs" : 1592346941263
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import com.johnsnowlabs.nlp.SparkNLP\n",
        "import com.johnsnowlabs.nlp.annotator._\n",
        "import com.johnsnowlabs.nlp.base._\n",
        "import org.apache.spark.ml.{Pipeline, PipelineModel, Transformer}\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "import org.apache.spark.sql.functions.{udf,to_timestamp}\n",
        "import org.apache.spark.storage._\n",
        "import org.apache.spark.ml.feature._\n",
        "import org.apache.spark.ml.classification._\n",
        "import org.apache.spark.ml.linalg.DenseVector\n",
        "import org.apache.spark.ml.param.{Param, ParamMap}\n",
        "import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions.{col, explode, udf}\n",
        "import org.apache.spark.sql.types.{DataTypes, StructType}\n",
        "import org.apache.spark.ml.evaluation._\n",
        "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
        "\n",
        "\n",
        "val dataDir = sys.env(\"HOME\") + \"/recsys2020\"\n",
        "val dsName = \"val10k\"\n",
        "\n",
        "val classNames = Array(\n",
        "  \"retweet\",\n",
        "  \"retweet_with_comment\",\n",
        "  \"like\",\n",
        "  \"reply\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592345671170,
          "endTs" : 1592345678359
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val df = spark.read.parquet(dataDir + s\"/${dsName}.parquet\")\n",
        "\n",
        "val schema = new StructType()\n",
        "    .add(\"tweet_id\", StringType, true)\n",
        "    .add(\"user_id\", StringType, true)\n",
        "    .add(\"out_pred\", DoubleType, true)\n",
        "\n",
        "val preds = for(className <- classNames) yield spark.read.format(\"csv\")\n",
        "        .option(\"delimiter\", \",\")\n",
        "        .schema(schema)\n",
        "        .load(dataDir + s\"/out/${dsName}/${className}.csv\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592346827037,
          "endTs" : 1592346828214
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val udf_bool_to_int = udf[Double, Boolean](x => if (x) 1.0 else 0.0)\n",
        "\n",
        "val joined = classNames.zip(preds).foldLeft(df){ \n",
        "    case (j, (className, classPred)) => j.join(classPred, Seq(\"user_id\", \"tweet_id\"), \"outer\")\n",
        "                                         .withColumnRenamed(\"out_pred\", \"pred_\" + className)\n",
        "                                         .withColumn(\"has_\" + className, udf_bool_to_int(col(\"has_\" + className)))\n",
        "}\n",
        "joined"
      ],
      "outputs" : [
        {
          "execution_count" : 5,
          "data" : {
            "text/plain" : [
              "[user_id: string, tweet_id: string ... 26 more fields]"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "DataFrame"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1592347712035,
          "endTs" : 1592347723179
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Select (prediction, true label) and compute test error.\n",
        "\n",
        "val log_loss = { (label: Double, pred: Double) => -(label * math.log(pred) + (1 - label) * math.log(1 - pred)) }\n",
        "\n",
        "for (className <- classNames)\n",
        "{\n",
        "  val metrics = new BinaryClassificationMetrics(\n",
        "    joined.select(col(\"pred_\" + className), col(\"has_\" + className)).rdd.map{row => (row.getDouble(0), row.getDouble(1))}\n",
        "  )\n",
        "\n",
        "  println(s\"${className} PRAUC = ${metrics.areaUnderPR}\")\n",
        "  println(s\"${className} ROCAUC = ${metrics.areaUnderROC}\")\n",
        "}"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "retweet PRAUC = 0.1475587328164478\n",
            "retweet ROCAUC = 0.5754907247228939\n",
            "retweet_with_comment PRAUC = 0.012144980635543947\n",
            "retweet_with_comment ROCAUC = 0.6017595169583473\n",
            "like PRAUC = 0.5139128386938798\n",
            "like ROCAUC = 0.5922976237216836\n",
            "reply PRAUC = 0.03713096484535038\n",
            "reply ROCAUC = 0.5748480506721724\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    }
  ]
}